(this["webpackJsonppraveenoruganti-courses"]=this["webpackJsonppraveenoruganti-courses"]||[]).push([[270],{839:function(e,a,t){"use strict";t.r(a),a.default=" At its most fundamental, a database is responsible for the storage and retrieval of data for an application. A database can also be called a Database Management System (DBMS) because it\u2019s an application that manages access to a physical data store. The core functions of a database are to:\n\n- store data\n- update and delete data\n- return data according to a query\n- administer the database\n\nAnd when providing these data services, a database needs to be reliable, efficient, and correct. It turns out that doing all these things at once is fairly complex.\n\n**Transactions**\nA transaction is a series of database operations that are considered to be a \"single unit of work\". The operations in a transaction either all succeed, or they all fail. In this way, the notion of a transaction supports data integrity when part of a system fails. This is formalized in the \"ACID\" properties:\n\n**Atomicity** - all operations succeed or fail together, i.e. the transaction is an \"atomic\" unit\n**Consistency** - a successful transaction places the database in a valid state, that is, no schema violations\n**Isolation** - transactions can be executed concurrently\n**Durability** - a \"committed\" transaction is persisted to memory\n\nNot all databases choose to support ACID transactions, usually because they are prioritizing other optimizations that are hard or theoretically impossible to implement together. Usually relational databases do support ACID transactions, and non-relational databases don\u2019t.\n\nRegardless of ACID support, database transactions make changes that need to be consistent with the organization of data within the database. Next we\u2019ll look at the different ways a system designer can specify this data structure organization, called a schema, and the impacts these design choices have on performance.\n\n**Schemas**\nThe role of a schema is to define the shape of a data structure, and specify what kinds of data can go where. In databases specifically, a schema can specify database-level structures like tables and indexes, and also data-level constraints like field types (string, boolean, reference, etc.)\n\nSchemas can be strictly enforced across the entire database, loosely enforced on part of the database, or they might not exist at all. There can be one schema for the entire database, or different entries can have different schemas. As we'll see below, all of these variations can be valuable in different use cases.\n\nThe advantage of a schema when strictly enforced, is that it is safe to assume that any queries to the system will return data that conforms to the schema assumptions. As nice as these guarantees can be, they have some major drawbacks:\n\nComputationally expensive: to enforce a schema, the schema properties have to be confirmed on every, write, update, and delete.\nDifficult to scale: especially if the schema specifies how data entries can reference each other, maintaining these constraints becomes more difficult as the reference span clusters and schema rules need to be verified across the network.\nThe last important feature of databases we\u2019ll talk about before jumping into specific models is scaling - how to respond to increasing database demands in a system.\n\n**Scaling**\nIt is more important than ever to be able to implement databases in distributed clusters as dataset sizes continue to grow. Different databases are better and worse at scaling because of the features they provide. There are two kinds of scaling:\n\n- **Vertical Scaling**: adding compute (CPU) and memory (RAM, Disk, SSD) resources to a single computer.\n- **Horizontal Scaling**: adding more computers to a cluster\n\nVertical scaling is fairly straightforward, but has much lower overall memory capacity. Horizontal scaling on the other hand has much higher overall compute and storage capacity, and can be sized dynamically without downtime. The big drawback is that relational databases, the most popular database model, struggle to scale horizontally.\n\n**Types of Databases**\n\n- **Relational DB:**\n  - MS SQL\n  - MySQL\n  - IBM DB2\n  - PostgreSQL\n  - SQLite etc.\n- **Document DB:**\n  - Cassandra\n  - HBase\n  - Google Spanner\n  - RethinkDB\n  - MongoDB etc.\n- **Graph DB:**\n  - Neo4j\n  - Titan\n  - InfiniteGraph\n  - AllegroGraph\n  - Cypher\n  - SPARQL\n  - Gremlin\n  - Pregel.\n- **Key-Value Store:**\n  - Redis\n  - DynamoDB\n  - CosmosDB\n  - Memcached\n  - Hazelcast.\n- **Column-Family Database:**\n  - Cassandra\n  - HBase\n  - CosmosDB.\n- **Search Engine Database:**\n  - Elasticsearch\n  - Splunk\n  - Solr.\n- **Time Series Database:**\n  - InfluxDB\n  - Kdb+\n  - Prometheus.\n\n**Relational Databases**\n\nAll databases need a data model to specify logical organization and rules of the data. A relational database is simply a database that uses a relational data model, which organizes data in tables with rows of data entries and columns of predetermined data types. Relationships between tables are represented with foreign key columns that reference the primary key columns of other tables.\n\nMost importantly, relational data models strictly enforce constraints to ensure that data values and relationships are always valid against the schema. ACID transactions are almost always implemented to ensure schema conformance.\n\nRelational databases are also called SQL databases because SQL (Structured Query Language) is the standard query language for relational models. SQL is declarative, meaning the requesting entity tells the database what it wants, but the database, specifically the query planner, decides how to get it. Tuning the query planner is one of the primary optimization techniques for relational databases.\n\nWhen data is frequently accessed by the same column, we can add an index on that column to speed up the search. An index is essentially a table that has a copy of the column of interest and a foreign key reference to the original table.\n\nDatabases support special ordering data structures on indices to make access faster than just scanning row by row. However this performance boost on reads is balanced by slower writes, because each index needs to get updated in addition to the primary table.\n\nRelational databases are almost always CP databases because guaranteeing consistency is important to upholding the relational model, and making sure that no matter what transactions occur, the database is always in a valid state.\n\n**When to use**\n\nLet's look at an example to build an intuitive understanding of when all the work relational databases do to enforce schema constraints is worth it. In this simple example, we want to build a hospital a data system to support safe and accurate medical care. We can store the data in three tables: patient information, doctor information, and patient visits.\n\nWe\u2019d like to be able to look up patients quickly, and in a clinical context patient data can come up in a lot of different ways. In one case we might need to look up a patient by name, like when they check in. Another situation might need to look up by the MRN (Medical Reference Number), like when a doctor prescribes a medication. To make sure the lookup is fast in both cases we\u2019ll put two indices on the patient table: one on the Name column, and one on the MRN column.\n\nTo make sure the hospital can track a patient's medical history, the visits table needs to reference both the patient table and doctor table. We also want the patient table to reference the doctor table to note who a patient\u2019s primary care physician is. We can already see in this very simplistic view of medical data how many relationships we need between tables. This is a sign that the relational model is a good fit.\n\nEven if this medical data is distributed over a cluster, it is very important that the response is correct. The personal impacts could be severe if the database didn\u2019t provide the most up to date information on a patient's medical care. This need for correctness is a sign that the relational model is a good fit. As we'll see, not all use cases have such strong requirements, and so other non-relational models can be considered.\n\n![screenshot of the app](https://praveenoruganti.github.io/courses/images/systemdesign/relationaldb.jpg)\n\nIn summary, relational databases are best when:\n\n- there are many-to-many relationships between entries\n- data needs to follow the predetermined schema\n- relationships between data always need to be accurate\n\nThe top industry technologies for relational databases are:\n\n- MySQL\n- Oracle\n- PostgresQL\n\n**Disadvantages**\n\nThe biggest disadvantage of relational databases is that they are hard to scale over distributed clusters (horizontal scaling). Relational databases are most useful when there are many relationships in the data, so no matter what way you split up the data there will be relationships between data entries on different nodes.\n\nWhen these cross-node relationships get updated, the nodes have to communicate with each other to \u201cnormalize\u201d (keep in sync) the data. As a result, the database operations get slower because network communication is slower. You can learn more about these design tradeoffs in our article about data replication and partitioning (coming soon).\n\nThey also aren't particularly advantageous if the data doesn't have a lot of references, doesn't easily conform to a single schema, or changes shape frequently. The equipment around enforcing schemas becomes unnecessary optimization and slows down operations.\n\nIncreasingly, distributed systems are moving away from exclusively using relational models particularly because of difficulties around maintaining relational guarantees on a cluster and a need for more flexibility around schemas.\n\nIt's important now to be able to choose what kind of database is relevant to the data and use case at hand. Some databases implement \"multi-model'' support, supporting both relational and non-relational models. Some databases are only non-relational, though these tend to be experimental or less mature systems.\n\nIn the next section, we'll give you an overview of the multitude of non-relational database options available, so you can choose the best database approaches for any system design.\n\n**Non-Relational databases**\n\nThe core question facing system designers today when choosing a database is given the structure of your data, what model do you want to choose to store it with? Non-relational databases are optimized for specific use cases that need scalability, schema flexibility, or specialized query support. As you'll see in this section, there are many kinds of non-relational databases. We'll go over a few of the most important to know when designing systems.\n\nNon-Relational Databases are often called NoSQL databases because they can use other query languages to optimize for their use case. But often non-relational databases will implement SQL or SQL-like query support to make developer\u2019s lives easier. The underlying execution of these queries, however, will be very different in relational and non-relational systems.\n\nNon-relational databases are either AP databases or CP databases, because they\u2019re targeting specific use cases that have varying priorities between availability and consistency. In the case of AP non-relational databases, the model of eventual consistency is used to make sure that consistency still happens over time, it\u2019s just not guaranteed exactly after a transaction completes.\n\n**Graph Database**\n\nGraph databases model data with nodes and edges. They are the most similar of the non-relational databases to a relational data model, because they also are good at representing data with lots of relationships. The main benefit of a graph database is that queries don't need joins to follow relationship edges, because data isn't stored in tables. So they're quite well suited for queries that traverse many edges of a graph, such as social network analytics.\n\nThe top graph databases in the industry are Neo4J and CosmosDB.\n\n**Document Store**\n\nDocument stores are usually simple JSON objects stored with a key identifier. Documents represent a set of information pertaining to a single topic, that in a relational database could be spread out over different tables. For example, a document store might archive medical records related to a single patient so that only one document needs to be accessed at a time, and all the relevant information is there.\n\nNotably, documents can have a variety of different schemas, which makes it easy to update a single document without updating the entire database. For example, a news outlet might choose to start adding a location field to their articles, and in a document store the location field can be added to new documents without having to update old ones.\n\nThe top document store databases in the industry are MongoDB, Couchbase, Firebase, CouchDB, and DynamoDB.\n\n**Key-Value Store**\n\nA Key-Value store is similar to a document store, but the data stored in the value is opaque. The key value store has no notion of what is stored in the value, so it only provides simple read, overwrite, and delete operations.\n\nThere are no schemas, no joins or indices - you can think of it as a very large hash table. Because of this minimal overhead they are easy to scale. Key-value stores are particularly suitable for caching implementations.\n\nWhen the values need to be large, this kind of database is referred to as an Object Store, or Blob Store. In this case, the data might be serialized and optimized for large file sizes. Use cases include videos, images, audio, disk images, and log binaries.\n\nThe top key-value stores in the industry are Redis, DynamoDB, CosmosDB, Memcached, and Hazelcast.\n\n**Column-Family Database**\n\nColumn families are a set of columns that are typically retrieved together. A column-family database models data in tables like a relational databases, but stores column families together in files instead of rows, and doesn't enforce relational constraints.\n\nFor data with strong column-family access patterns, this model boosts performance by limiting how much data needs to be read. And since columns tend to hold a repeating type of information, they can be compressed to save space, which is especially helpful if the data is sparse.\n\nFor example, a column-family database might group name columns, so regardless of which components of a name someone has, (because names are complex!) all the possible fields will be retrieved together. This model also effectively partitions the data table for horizontal scaling.\n\nThe top column-family databases in the industry are Cassandra, HBase, and CosmosDB.\n\n**Search Engine Database**\n\nA search engine database provides the specialized feature of full text search over very large amounts of unstructured text data. The data can possibly come from multiple sources, and users of the database may also want \"fuzzy search\", meaning the results may not exactly match the search string.\n\nA well-known example of this is searching websites (like Google), but it can also be valuable for example in being able to search and debug large volumes of system logs.\n\nThe top search engine databases in the industry are Elasticsearch, Splunk, and Solr.\n\n**Time Series Database**\n\nA time series database is optimized for data entries that need to be strictly ordered by time. The main use case is storing real time data streams from system monitors.\n\nFor example, a huge social network service might want to log every time a user runs into an error, and feed all the different error-handling services into a single searchable time-series database for engineers to easily track down and debug problems.\n\nTime series databases are write heavy, and usually provide services for sorting streams as they come in to make sure they are appended in the correct order. These databases can be easily partitioned by time range.\n\nThe top time series databases in the industry are InfluxDB, Kdb+, and Prometheus.\n\n**Summary of different databases**\n\nWhen choosing a database, it is important to consider data size, structure, relationships, and how important it is to enforce schemas and ensure consistency. Remember that especially in large systems, one database might not be able to do everything you need, so it's ok to choose more than one.\n\nAs scale becomes more important, relational databases become too expensive to maintain, so start looking at non-relational alternatives for parts of the system that don't need strong schemas and consistency guarantees. For reference, we've summarized the key points for each kind of database:\n\n**Relational database**\n\n- many-to-many relationships\n- data and data relationships need to strictly follow schema\n- consistent transactions are important\n- hard to scale because relationships are hard to partition effectively\n\n**Graph database**\n\n- many-to-many relationships (graph structure)\n- fast at following graph edges\n- suited to complex network analytics\n- less mature technology than Relational\n\n**Document store**\n\n- isolated documents\n- retrieve by a key\n- documents with different schemas that are easy to update\n- easy to scale\n\n**Key-value store / object store**\n\n- opaque values\n- no schema or relationships known to the database\n- very simple operations\n- easy to scale\n\n**Column-family database**\n\n- groups related columns for storage (easy to scale)\n- memory effective for sparse data\n\n**Search engine database**\n\n- large amounts of unstructured data\n- full text search or fuzzy search service\n\n**Time series database**\n\n- data is ordered by time\n- many data streams\n- real time entry ordering functionality\n "}}]);